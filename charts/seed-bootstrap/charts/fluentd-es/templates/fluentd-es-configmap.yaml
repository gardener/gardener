apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-es-config
  namespace: {{ .Release.Namespace }}
  labels:
{{ toYaml .Values.fluentd.labels | indent 4 }}
data:
  input.conf: |-
    # Takes the messages sent over TCP
    <source>
      @type forward
      @log_level warn
      port 24224
      bind 0.0.0.0
    </source>

  output.conf: |-
    # Decide which is shoot record and which is not
    <match kubernetes.**>
      @id rewrite_tag_filter
      @type rewrite_tag_filter
      @log_level warn
      <rule>
        key $.kubernetes.namespace_name
        pattern ^(shoot.*)
        tag $1
      </rule>
      <rule>
        key $.kubernetes.namespace_name
        pattern ^shoot.*
        invert true
        tag seed
      </rule>
    </match>

    <filter **>
      @type elasticsearch_genid
    </filter>

    # Match shoot namespace.
    <match shoot**>
      @id elasticsearch_dynamic
      @type elasticsearch
      @log_level warn
      host elasticsearch-logging.${tag}.svc

      # Drop chunks failed with the following errors
      ignore_exceptions ["Faraday::ClientError", "Elasticsearch::Transport::Transport::ServerError"]
      exception_backup false

      @include /etc/fluent/config.d/es_plugin.options
      <buffer tag, time>
        @type file
        # Limit the number of queued chunks
        queued_chunks_limit_size 4096
        # The number of threads of output plugins, which is used to write chunks in parallel
        flush_thread_count 32
        # the size limitation of this buffer plugin instance
        total_limit_size 6GB
        @include /etc/fluent/config.d/buffer.options
        path /gardener/fluentd-buffers/kubernetes.shoot.buffer
      </buffer>
      # avoiding backup of unrecoverble errors
      <secondary>
        @type null
      </secondary>
    </match>

    <match **>
      @id elasticsearch_static
      @type elasticsearch
      @log_level warn
      host elasticsearch-logging.{{ .Release.Namespace }}.svc
      @include /etc/fluent/config.d/es_plugin.options
      template_name gardener
      template_file /etc/fluent/config.d/default.template
      <buffer tag, time>
        @type file
        # Limit the number of queued chunks
        queued_chunks_limit_size 40
        # The number of threads of output plugins, which is used to write chunks in parallel
        flush_thread_count 8
        # the size limitation of this buffer plugin instance
        total_limit_size 2GB
        @include /etc/fluent/config.d/buffer.options
        path /gardener/fluentd-buffers/kubernetes.{{ .Release.Namespace }}.buffer
      </buffer>
      <secondary>
        @type null
      </secondary>
    </match>

  system.conf: |-
    <system>
      root_dir /gardener/fluentd-buffers/
    </system>

  es_plugin.options: |-
    port {{ .Values.global.elasticsearchPorts.db }}
    logstash_format true
    # use _hash as request id
    id_key _hash
    reconnect_on_error true
    # gives enough time fluentd to read the response
    request_timeout 30s
    # this is only for debug. When flush take more time than this it will produce warning
    slow_flush_log_threshold 60
    # Do not wait ES to tell you what version is.
    verify_es_version_at_startup false
    # just hardcode that version number
    default_elasticsearch_version 6
    # we have time field from the docker runtime
    # include_timestamp false
    time_key time
    # remove tag from the log content
    include_tag_key false
    remove_keys _hash, time

  buffer.options: |-
    chunk_limit_size 50MB                                # the max size of each chunks
    chunk_full_threshold 0.9                             # the percentage of chunk size threshold for flushing
    timekey 300                                          # chunks per 5m

    flush_mode interval
    flush_interval 60s                                   # flush/write chunks per specified time
    timekey_wait 0                                       # delay for flush
    flush_at_shutdown true                               # flush/write all buffer chunks at shutdown
    flush_thread_interval 30.0                           # the sleep interval seconds of threads to wait next flush trial (when no chunks are waiting)

    overflow_action drop_oldest_chunk                    # how output plugin behaves when its buffer queue is full

    retry_type periodic                                  # output plugin will retry periodically with fixed intervals (configured via retry_wait)
    retry_wait 75                                        # seconds to wait before next retry to flush
    retry_randomize false
    retry_max_times 4                                    # all chunks in the queue are discarded when when the number of reties exceeds retry_max_times

  default.template: |-
    {
      "index_patterns": ["logstash-*"],
      "settings": {
        "index": {
          "number_of_shards": "3",
          "number_of_replicas": "0",
          "refresh_interval": "60s",
          "translog": {
            "durability": "async"
          }
        }
      }
    }
