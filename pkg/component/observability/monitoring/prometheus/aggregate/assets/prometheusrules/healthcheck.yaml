apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: healthcheck
spec:
  groups:
    - name: healthcheck
      rules:
        # healthcheck{task="target:down"} is present for each scrape job target that is down.
        # The scrape job for the shoot prometheus is excluded,
        # because it might be observed as down when a shoot control plane is being deleted.
        - record: healthcheck
          expr: up{job!="shoot-prometheus"} == 0
          labels:
            task: target:down

        # healthcheck{task="scrape_pool:empty"} is present for each scrape pool that is empty.
        # The scrape pool for the shoot prometheus is excluded,
        # because it is expected to be empty if there are no shoots in the seed.
        - record: healthcheck
          expr: prometheus_target_scrape_pool_targets{scrape_job!="serviceMonitor/garden/aggregate-shoot-prometheus/0"} == 0
          labels:
            task: scrape_pool:empty

        # healthcheck{task="scrape:empty"} is present for each scrape job target that yields no samples after metric relabeling.
        # The scrape job for the shoot prometheus is excluded,
        # because it might yield no samples when a shoot control plane is being deleted.
        - record: healthcheck
          expr: scrape_samples_post_metric_relabeling{job!="shoot-prometheus"} == 0
          labels:
            task: scrape:empty

        # healthcheck{task="rule_evaluation:unknown_status"} is present when the evaluation status of these healthcheck rules is unknown.
        - record: healthcheck
          expr: absent(prometheus_rule_group_iterations_total{rule_group=~".*;healthcheck"})
          labels:
            task: rule_evaluation:unknown_status

        # healthcheck{task="rule_evaluation:first_cycle"} is present in the first rule evaluation cycle.
        #
        # The first cycle is intentionally treated as unhealthy on a fresh Prometheus deployment
        # or after a prolonged downtime.
        #
        # This prevents flaky end-to-end PR validation tests:
        # Prometheus reports unhealthy until these healthcheck rules are ready to detect problems.
        #
        # Rationale: within an evaluation cycle, the order of scrapes and rule evaluations is undefined.
        # Some scrape jobs may run only after the first evaluation of the healthcheck rules,
        # so only the second evaluation can reliably confirm there are no issues.
        - record: healthcheck
          expr: max_over_time(prometheus_rule_group_iterations_total{rule_group=~".*;healthcheck"}[5m]) == 0
          labels:
            task: rule_evaluation:first_cycle

        # healthcheck{task="metering:absent"} is present when the federated metering metrics are missing.
        - record: healthcheck
          expr: absent(metering:cpu_requests:sum_by_namespace{namespace="garden"})
          labels:
            task: metering:absent

        # healthcheck:up indicates the overall health status.
        #
        # A query for `healthcheck:up` can return
        # - no data points: this state is unhealthy. The healthcheck rules have not been executed yet or are not working properly.
        # - a value == 0:   this state is unhealthy. See the `healthcheck` time series for details.
        # - a value == 1:   this state is healthy. The healthcheck rules are working and there are no issues.
        - record: healthcheck:up
          expr: |2
              count(healthcheck) * 0
            or
              vector(1)
