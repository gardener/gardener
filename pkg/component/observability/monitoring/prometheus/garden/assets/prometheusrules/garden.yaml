apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: garden
spec:
  groups:
  - name: garden
    rules:
    - alert: DashboardDown
      expr: |
        probe_success{job     = "blackbox-dashboard",
                      purpose = "availability"}
        == 0
      for: 5m
      labels:
        severity: critical
        topology: garden
        service: dashboard
      annotations:
        summary: Dashboard is Down in landscape {{$externalLabels.landscape}}
        description: >
          The http health probe to the Gardener Dashboard failed for at least 5
          minutes (instance is {{$labels.instance}}).
          (Status code is
          {{printf `probe_http_status_code{job      = "blackbox-dashboard"
          ,                                purpose  = "availability"
          ,                                instance = "%s"}`
          $labels.instance
          | query | first | value}}).

<<- if .GardenerDiscoveryServerEnabled >>
    - alert: DiscoveryServerDown
      expr: |
        probe_success{job     = "blackbox-discovery-server",
                      purpose = "availability"}
        == 0
      for: 5m
      labels:
        severity: critical
        topology: garden
        service: discovery-server
      annotations:
        summary: Discovery Server is Down in landscape {{$externalLabels.landscape}}
        description: >
          The http health probe to the Gardener Discovery Server failed for at least 5
          minutes (instance is {{$labels.instance}}).
          (Status code is
          {{printf `probe_http_status_code{job      = "blackbox-discovery-server"
          ,                                purpose  = "availability"
          ,                                instance = "%s"}`
          $labels.instance
          | query | first | value}}).
<<- end >>

    - alert: ApiServerDown
      expr: |
        probe_success{job     = "blackbox-apiserver",
                      purpose = "availability"}
        == 0
      for: 2m
      labels:
        severity: critical
        topology: garden
        service: apiserver
      annotations:
        summary: ApiServer is Down in landscape {{$externalLabels.landscape}}
        description: >
          The http health probe to the Api Server failed for at least 2 minutes
          (instance is {{$labels.instance}}).

          (Status code is
          {{printf `probe_http_status_code{job      = "blackbox-apiserver"
          ,                                purpose  = "availability"
          ,                                instance = "%s"}`
          $labels.instance | query | first | value}}).

    - alert: GardenerApiServerDown
      expr: |
        probe_success{job     = "blackbox-gardener-apiserver",
                      purpose = "availability"}
        == 0
      for: 2m
      labels:
        severity: critical
        topology: garden
        service: gardener-apiserver
      annotations:
        summary: >-
          Gardener ApiServer is Down in landscape {{$externalLabels.landscape}}
        description: >
          The http health probe to the Gardener Api Server failed for at least 2
          minutes (instance is {{$labels.instance}}).

          (Status code is
          {{printf `probe_http_status_code{job      = "blackbox-gardener-apiserver"
          ,                                purpose  = "availability"
          ,                                instance = "%s"}`
          $labels.instance
          | query | first | value}}).

    - alert: ProjectStuckInDeletion
      expr: |
          avg(garden_projects_status{phase="Terminating"}) without (instance)
          and
          avg(garden_projects_status{phase="Terminating"} offset 1w) without (instance)
      for: 5m
      labels:
        severity: warning
        topology: garden
      annotations:
        summary: Project {{$labels.name}} stuck in {{$labels.phase}} phase in landscape {{$externalLabels.landscape}}
        description: Project {{$labels.name}} has been stuck in {{$labels.phase}} phase for 1 week. Please investigate.

    - alert: GardenerControllerManagerDown
      expr: |
        absent( up{job = "gardener-controller-manager"} == 1 )
      for: 10m
      labels:
        severity: critical
        topology: garden
        service: gardener-controller-manager
      annotations:
        summary: >-
          Gardener Controller Manager is Down in landscape
          {{$externalLabels.landscape}}
        description: >
          Scraping the /metrics endpoint of the Gardener Controller Manager
          failed for at least 10 minutes.

    - alert: GardenerMetricsExporterDown
      expr: |
        absent(
          up{job="gardener-metrics-exporter"}
          == 1
        )
      for: 15m
      labels:
        severity: critical
        topology: garden
      annotations:
        summary: >-
          The gardener-metrics-exporter is down in landscape:
          {{$externalLabels.landscape}}.
        description: >
          The gardener-metrics-exporter is down. Alert conditions for the
          gardenlets, shoots, and seeds cannot be detected. Metering will also not
          work because there are no metrics.

    - alert: MissingGardenMetrics
      expr: |
        scrape_samples_scraped{job="gardener-metrics-exporter"}
        == 0
      for: 15m
      labels:
        severity: critical
        topology: garden
      annotations:
        summary: >-
          The gardener-metrics-exporter is not exposing metrics in landscape:
          {{$externalLabels.landscape}}
        description: >
          The gardener-metrics-exporter is not exposing any metrics. Alert
          conditions for the gardenlets, shoots, and seeds cannot be detected.
          Metering will also not work because there are no metrics.

    - alert: PodFrequentlyRestarting
      expr: |
        increase(
          kube_pod_container_status_restarts_total[1h]
        ) > 5
      for: 10m
      labels:
        severity: warning
        topology: garden
      annotations:
        summary: Pod is restarting frequently
        description: >
          Pod {{$labels.namespace}}/{{$labels.pod}} in landscape
          {{$externalLabels.landscape}} was restarted more than 5 times within the
          last hour. The pod is running on the garden cluster.
